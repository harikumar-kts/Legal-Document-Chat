{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Loading Docling related modules`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docling.chunking import HybridChunker\n",
    "from docling_core.types.doc import ImageRefMode\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.pipeline.simple_pipeline import SimplePipeline\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption, WordFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode, EasyOcrOptions\n",
    "\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain_elasticsearch import ElasticsearchStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Initialize the Docling converter object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PdfPipelineOptions(\n",
    "    do_ocr=True,\n",
    "    images_scale=1.0,\n",
    "    do_table_structure=True,\n",
    "    generate_page_images=True,\n",
    "    generate_picture_images=True,\n",
    "    ocr_options=EasyOcrOptions(\n",
    "        lang=[\"en\"], \n",
    "        use_gpu=True,\n",
    "        force_full_page_ocr=True, \n",
    "    ),\n",
    "    table_structure_options=dict(\n",
    "        do_cell_matching=False,\n",
    "        mode=TableFormerMode.ACCURATE\n",
    "    ),\n",
    ")\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    allowed_formats=[\n",
    "        InputFormat.PDF,\n",
    "        InputFormat.IMAGE,\n",
    "        InputFormat.DOCX,\n",
    "        InputFormat.HTML,\n",
    "        InputFormat.XLSX,\n",
    "        InputFormat.PPTX,\n",
    "        InputFormat.ASCIIDOC,\n",
    "        InputFormat.MD,\n",
    "    ],\n",
    "    format_options={\n",
    "        InputFormat.DOCX: WordFormatOption(\n",
    "            pipeline_cls=SimplePipeline\n",
    "        ),\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Parse the document and create markdown file (Optional**)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = doc_converter.convert(\n",
    "#     source=\"../data/table.pdf\"\n",
    "# )\n",
    "# _filename = Path(f\"{result.input.file.stem}-with-image-refs.md\")\n",
    "# result.document.save_as_markdown(_filename, image_mode=ImageRefMode.REFERENCED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Input Variables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"../data/First Edition Arabic 2023-44.pdf\"\n",
    "\n",
    "TOP_K = 3\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Context information is below.\n",
    "    {context}\n",
    "    Given the context information and not prior knowledge, answer the query.\n",
    "    Query: {input}\n",
    "    Answer:\n",
    "    \"\"\",\n",
    ")\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS if FILE_PATH.endswith(\".xlsx\") else ExportType.MARKDOWN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create Object for Langchain Docling Loader and load the document`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "docling_loaded_file = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    converter=doc_converter,\n",
    "    export_type=EXPORT_TYPE,\n",
    ").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create the documents for the indexing from the Docling loaded documents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header_2': '2006 aiuuJ (25)'}, page_content=\"- ri\\n- LoJ 2 L699 'U QnJl\\n- 49\\n- L2i\")]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
    "    documents = docling_loaded_file\n",
    "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
    "    splitter = MarkdownHeaderTextSplitter(\n",
    "        headers_to_split_on=[(\"#\", \"Header_1\"),(\"##\", \"Header_2\"),(\"###\", \"Header_3\"),],\n",
    "    )\n",
    "    documents = [split for doc in docling_loaded_file for split in splitter.split_text(doc.page_content)]\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")\n",
    "\n",
    "documents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': '../data/EmployeeSampleData/Employee Sample Data.xlsx', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'table', 'prov': []}], 'origin': {'mimetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'binary_hash': 17978778108143012858, 'filename': 'Employee Sample Data.xlsx'}}}\n",
      "EEID, 1 = Full Name. EEID, 2 = Job Title. EEID, 3 = Department. EEID, 4 = Business Unit. EEID, 5 = Gender. EEID, 6 = Ethnicity. EEID, 7 = Age. EEID, 8 = Hire Date. EEID, 9 = Annual Salary. EEID, 10 = Bonus %. EEID, 11 = Country. EEID, 12 = City. EEID, 13 = Exit Date. E02387, 1 = Emily Davis. E02387, 2 = Sr. Manger. E02387, 3 = IT. E02387, 4 = Research & Development. E02387, 5 = Female. E02387, 6 = Black. E02387, 7 = 55. E02387, 8 = 2016-04-08 00:00:00. E02387, 9 = 141604. E02387, 10 = 0.15. E02387, 11 = United States. E02387, 12 = Seattle. E02387, 13 = 2021-10-16 00:00:00. E04105, 1 = Theodore Dinh. E04105, 2 = Technical Architect. E04105, 3 = IT. E04105, 4 = Manufacturing. E04105, 5 = Male. E04105, 6 = Asian. E04105, 7 = 59. E04105, 8 = 1997-11-29 00:00:00. E04105, 9 = 99975. E04105, 10 = 0. E04105, 11 = China. E04105, 12 = Chongqing. E04105, 13 = . E02572, 1 = Luna Sanders. E02572, 2 = Director. E02572, 3 = Finance. E02572, 4 = Speciality Products. E02572, 5 = Female. E02572, 6 = Caucasian. E02572, 7 = 50. E02572, 8 = 2006-10-26 00:00:00. E02572, 9 = 163099. E02572, 10 =\n",
      "\n",
      "\n",
      "{'source': '../data/EmployeeSampleData/Employee Sample Data.xlsx', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'table', 'prov': []}], 'origin': {'mimetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'binary_hash': 17978778108143012858, 'filename': 'Employee Sample Data.xlsx'}}}\n",
      "0.2. E02572, 11 = United States. E02572, 12 = Chicago. E02572, 13 = . E02832, 1 = Penelope Jordan. E02832, 2 = Computer Systems Manager. E02832, 3 = IT. E02832, 4 = Manufacturing. E02832, 5 = Female. E02832, 6 = Caucasian. E02832, 7 = 26. E02832, 8 = 2019-09-27 00:00:00. E02832, 9 = 84913. E02832, 10 = 0.07. E02832, 11 = United States. E02832, 12 = Chicago. E02832, 13 = . E01639, 1 = Austin Vo. E01639, 2 = Sr. Analyst. E01639, 3 = Finance. E01639, 4 = Manufacturing. E01639, 5 = Male. E01639, 6 = Asian. E01639, 7 = 55. E01639, 8 = 1995-11-20 00:00:00. E01639, 9 = 95409. E01639, 10 = 0. E01639, 11 = United States. E01639, 12 = Phoenix. E01639, 13 = . E00644, 1 = Joshua Gupta. E00644, 2 = Account Representative. E00644, 3 = Sales. E00644, 4 = Corporate. E00644, 5 = Male. E00644, 6 = Asian. E00644, 7 = 57. E00644, 8 = 2017-01-24 00:00:00. E00644, 9 = 50994. E00644, 10 = 0. E00644, 11 = China. E00644, 12 = Chongqing. E00644, 13 = . E01550, 1 = Ruby Barnes. E01550, 2 = Manager. E01550, 3 = IT. E01550, 4 = Corporate. E01550, 5 = Female. E01550, 6 = Caucasian. E01550, 7 = 27. E01550, 8 = 2020-07-01 00:00:00.\n",
      "\n",
      "\n",
      "{'source': '../data/EmployeeSampleData/Employee Sample Data.xlsx', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/tables/0', 'parent': {'$ref': '#/groups/0'}, 'children': [], 'label': 'table', 'prov': []}], 'origin': {'mimetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'binary_hash': 17978778108143012858, 'filename': 'Employee Sample Data.xlsx'}}}\n",
      "E01550, 9 = 119746. E01550, 10 = 0.1. E01550, 11 = United States. E01550, 12 = Phoenix. E01550, 13 = . E04332, 1 = Luke Martin. E04332, 2 = Analyst. E04332, 3 = Finance. E04332, 4 = Manufacturing. E04332, 5 = Male. E04332, 6 = Black. E04332, 7 = 25. E04332, 8 = 2020-05-16 00:00:00. E04332, 9 = 41336. E04332, 10 = 0. E04332, 11 = United States. E04332, 12 = Miami. E04332, 13 = 2021-05-20 00:00:00. E04533, 1 = Easton Bailey. E04533, 2 = Manager. E04533, 3 = Accounting. E04533, 4 = Manufacturing. E04533, 5 = Male. E04533, 6 = Caucasian. E04533, 7 = 29. E04533, 8 = 2019-01-25 00:00:00. E04533, 9 = 113527. E04533, 10 = 0.06. E04533, 11 = United States. E04533, 12 = Austin. E04533, 13 = . E03838, 1 = Madeline Walker. E03838, 2 = Sr. Analyst. E03838, 3 = Finance. E03838, 4 = Speciality Products. E03838, 5 = Female. E03838, 6 = Caucasian. E03838, 7 = 34. E03838, 8 = 2018-06-13 00:00:00. E03838, 9 = 77203. E03838, 10 = 0. E03838, 11 = United States. E03838, 12 = Chicago. E03838, 13 = . E00591, 1 = Savannah Ali. E00591, 2 = Sr. Manger. E00591, 3 = Human Resources. E00591, 4 = Manufacturing. E00591, 5 = Female. E00591, 6 = Asian.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in documents[:3]:\n",
    "    print(idx.metadata)\n",
    "    print(idx.page_content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticsearch_client = Elasticsearch(\n",
    "    hosts=\"https://360399a232d44176a9811dcf98c25240.eastus2.azure.elastic-cloud.com:443\",\n",
    "    basic_auth=(\"elastic\", \"zfNThaF3pna6JHmcGPIsntKP\")\n",
    ")\n",
    "\n",
    "elasticsearch_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "BulkIndexError",
     "evalue": "269 document(s) failed to index.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkIndexError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mElasticsearchStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mes_connection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melasticsearch_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_index_xlsx_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\langchain_elasticsearch\\vectorstores.py:1242\u001b[0m, in \u001b[0;36mElasticsearchStore.from_documents\u001b[1;34m(cls, documents, embedding, bulk_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1239\u001b[0m elasticsearchStore \u001b[38;5;241m=\u001b[39m ElasticsearchStore(embedding\u001b[38;5;241m=\u001b[39membedding, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;66;03m# Encode the provided texts and add them to the newly created index.\u001b[39;00m\n\u001b[1;32m-> 1242\u001b[0m \u001b[43melasticsearchStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbulk_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elasticsearchStore\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:287\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    286\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\langchain_elasticsearch\\vectorstores.py:1082\u001b[0m, in \u001b[0;36mElasticsearchStore.add_texts\u001b[1;34m(self, texts, metadatas, ids, refresh_indices, create_index_if_not_exists, bulk_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_texts\u001b[39m(\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1057\u001b[0m     texts: Iterable[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1064\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run more texts through the embeddings and add to the store.\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;124;03m        List of ids from adding the texts into the store.\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1082\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefresh_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_index_if_not_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_index_if_not_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbulk_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\helpers\\vectorstore\\_sync\\vectorstore.py:171\u001b[0m, in \u001b[0;36mVectorStore.add_texts\u001b[1;34m(self, texts, metadatas, vectors, ids, refresh_indices, create_index_if_not_exists, bulk_kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m         firstError \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39merrors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m    170\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst error reason: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfirstError\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreason\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 171\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo texts to add to index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\helpers\\vectorstore\\_sync\\vectorstore.py:158\u001b[0m, in \u001b[0;36mVectorStore.add_texts\u001b[1;34m(self, texts, metadatas, vectors, ids, refresh_indices, create_index_if_not_exists, bulk_kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(requests) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m         success, failed \u001b[38;5;241m=\u001b[39m \u001b[43mbulk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequests\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstats_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrefresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefresh_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbulk_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded texts \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:540\u001b[0m, in \u001b[0;36mbulk\u001b[1;34m(client, actions, stats_only, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# make streaming_bulk yield successful results so we can count them\u001b[39;00m\n\u001b[0;32m    539\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myield_ok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstreaming_bulk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_status\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhelpers.bulk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[misc]\u001b[39;49;00m\n\u001b[0;32m    542\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# go through request-response pairs and detect failures\u001b[39;49;00m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mok\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstats_only\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:453\u001b[0m, in \u001b[0;36mstreaming_bulk\u001b[1;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, ignore_status, retry_on_status, span_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(max_backoff, initial_backoff \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (attempt \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbulk_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_process_bulk_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbulk_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbulk_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_on_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m            \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mok\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:359\u001b[0m, in \u001b[0;36m_process_bulk_chunk\u001b[1;34m(client, bulk_actions, bulk_data, otel_span, raise_on_exception, raise_on_error, ignore_status, *args, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    353\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _process_bulk_chunk_success(\n\u001b[0;32m    354\u001b[0m         resp\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    355\u001b[0m         bulk_data\u001b[38;5;241m=\u001b[39mbulk_data,\n\u001b[0;32m    356\u001b[0m         ignore_status\u001b[38;5;241m=\u001b[39mignore_status,\n\u001b[0;32m    357\u001b[0m         raise_on_error\u001b[38;5;241m=\u001b[39mraise_on_error,\n\u001b[0;32m    358\u001b[0m     )\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m gen\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\helpers\\actions.py:276\u001b[0m, in \u001b[0;36m_process_bulk_chunk_success\u001b[1;34m(resp, bulk_data, ignore_status, raise_on_error)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m ok, {op_type: item}\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BulkIndexError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m document(s) failed to index.\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors)\n",
      "\u001b[1;31mBulkIndexError\u001b[0m: 269 document(s) failed to index."
     ]
    }
   ],
   "source": [
    "ElasticsearchStore.from_documents(\n",
    "    texts=documents,\n",
    "    embedding=embedding,\n",
    "    es_connection=elasticsearch_client,\n",
    "    index_name=\"test_index_xlsx_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'took': 0, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1207, 'relation': 'eq'}, 'max_score': 1.0, 'hits': [{'_index': 'xlsx_index', '_id': 'phLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E02387', 'Full Name': 'Emily Davis', 'Job Title': 'Sr. Manger', 'Department': 'IT', 'Business Unit': 'Research & Development', 'Gender': 'Female', 'Ethnicity': 'Black', 'Age': 55, 'Hire Date': '2016-04-08T00:00:00', 'Annual Salary': 141604, 'Bonus %': 0.15, 'Country': 'United States', 'City': 'Seattle', 'Exit Date': '2021-10-16T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'rRLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E04332', 'Full Name': 'Luke Martin', 'Job Title': 'Analyst', 'Department': 'Finance', 'Business Unit': 'Manufacturing', 'Gender': 'Male', 'Ethnicity': 'Black', 'Age': 25, 'Hire Date': '2020-05-16T00:00:00', 'Annual Salary': 41336, 'Bonus %': 0, 'Country': 'United States', 'City': 'Miami', 'Exit Date': '2021-05-20T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'tBLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E03496', 'Full Name': 'Robert Yang', 'Job Title': 'Sr. Analyst', 'Department': 'Accounting', 'Business Unit': 'Speciality Products', 'Gender': 'Male', 'Ethnicity': 'Asian', 'Age': 31, 'Hire Date': '2017-11-04T00:00:00', 'Annual Salary': 97078, 'Bonus %': 0, 'Country': 'United States', 'City': 'Austin', 'Exit Date': '2020-03-09T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'zhLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E01754', 'Full Name': 'Owen Lam', 'Job Title': 'Sr. Business Partner', 'Department': 'Human Resources', 'Business Unit': 'Speciality Products', 'Gender': 'Male', 'Ethnicity': 'Asian', 'Age': 30, 'Hire Date': '2017-05-29T00:00:00', 'Annual Salary': 86317, 'Bonus %': 0, 'Country': 'China', 'City': 'Chengdu', 'Exit Date': '2017-07-16T00:00:00'}}, {'_index': 'xlsx_index', '_id': '4xLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E00502', 'Full Name': 'Natalia Salazar', 'Job Title': 'Sr. Analyst', 'Department': 'Accounting', 'Business Unit': 'Manufacturing', 'Gender': 'Female', 'Ethnicity': 'Latino', 'Age': 44, 'Hire Date': '2019-01-02T00:00:00', 'Annual Salary': 74691, 'Bonus %': 0, 'Country': 'Brazil', 'City': 'Manaus', 'Exit Date': '2020-07-08T00:00:00'}}, {'_index': 'xlsx_index', '_id': '5BLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E04000', 'Full Name': 'Skylar Carrillo', 'Job Title': 'Engineering Manager', 'Department': 'Engineering', 'Business Unit': 'Corporate', 'Gender': 'Female', 'Ethnicity': 'Latino', 'Age': 44, 'Hire Date': '2008-12-18T00:00:00', 'Annual Salary': 92753, 'Bonus %': 0.13, 'Country': 'United States', 'City': 'Austin', 'Exit Date': '2021-06-24T00:00:00'}}, {'_index': 'xlsx_index', '_id': '6BLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E00436', 'Full Name': 'Everly Walker', 'Job Title': 'HRIS Analyst', 'Department': 'Human Resources', 'Business Unit': 'Speciality Products', 'Gender': 'Female', 'Ethnicity': 'Caucasian', 'Age': 41, 'Hire Date': '2009-10-23T00:00:00', 'Annual Salary': 54415, 'Bonus %': 0, 'Country': 'United States', 'City': 'Seattle', 'Exit Date': '2014-01-22T00:00:00'}}, {'_index': 'xlsx_index', '_id': '7BLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E02966', 'Full Name': 'William Foster', 'Job Title': 'Field Engineer', 'Department': 'Engineering', 'Business Unit': 'Manufacturing', 'Gender': 'Male', 'Ethnicity': 'Caucasian', 'Age': 58, 'Hire Date': '2002-05-23T00:00:00', 'Annual Salary': 76354, 'Bonus %': 0, 'Country': 'United States', 'City': 'Phoenix', 'Exit Date': '2021-09-26T00:00:00'}}, {'_index': 'xlsx_index', '_id': '8RLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E01540', 'Full Name': 'Miles Salazar', 'Job Title': 'IT Coordinator', 'Department': 'IT', 'Business Unit': 'Manufacturing', 'Gender': 'Male', 'Ethnicity': 'Latino', 'Age': 36, 'Hire Date': '2010-12-23T00:00:00', 'Annual Salary': 53215, 'Bonus %': 0, 'Country': 'Brazil', 'City': 'Sao Paulo', 'Exit Date': '2014-03-27T00:00:00'}}, {'_index': 'xlsx_index', '_id': '8hLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E04474', 'Full Name': 'Mila Hong', 'Job Title': 'Test Engineer', 'Department': 'Engineering', 'Business Unit': 'Research & Development', 'Gender': 'Female', 'Ethnicity': 'Asian', 'Age': 30, 'Hire Date': '2017-05-22T00:00:00', 'Annual Salary': 86858, 'Bonus %': 0, 'Country': 'China', 'City': 'Chongqing', 'Exit Date': '2017-10-08T00:00:00'}}, {'_index': 'xlsx_index', '_id': '-RLqbpQBXUp6I3aU7ro2', '_score': 1.0, '_source': {'EEID': 'E00416', 'Full Name': 'Everleigh Fernandez', 'Job Title': 'Director', 'Department': 'Engineering', 'Business Unit': 'Research & Development', 'Gender': 'Female', 'Ethnicity': 'Latino', 'Age': 30, 'Hire Date': '2016-05-22T00:00:00', 'Annual Salary': 189702, 'Bonus %': 0.28, 'Country': 'Brazil', 'City': 'Manaus', 'Exit Date': '2020-12-21T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'ABLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E00440', 'Full Name': 'Jack Huynh', 'Job Title': 'Manager', 'Department': 'Marketing', 'Business Unit': 'Research & Development', 'Gender': 'Male', 'Ethnicity': 'Asian', 'Age': 27, 'Hire Date': '2018-09-25T00:00:00', 'Annual Salary': 114441, 'Bonus %': 0.1, 'Country': 'China', 'City': 'Chongqing', 'Exit Date': '2019-12-22T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'DhLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E01261', 'Full Name': 'Connor Simmons', 'Job Title': 'Analyst II', 'Department': 'Accounting', 'Business Unit': 'Speciality Products', 'Gender': 'Male', 'Ethnicity': 'Caucasian', 'Age': 55, 'Hire Date': '2007-04-05T00:00:00', 'Annual Salary': 52310, 'Bonus %': 0, 'Country': 'United States', 'City': 'Miami', 'Exit Date': '2018-10-12T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'KBLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E03131', 'Full Name': 'Ezekiel Reed', 'Job Title': 'Sr. Manger', 'Department': 'IT', 'Business Unit': 'Manufacturing', 'Gender': 'Male', 'Ethnicity': 'Caucasian', 'Age': 37, 'Hire Date': '2014-02-25T00:00:00', 'Annual Salary': 128984, 'Bonus %': 0.12, 'Country': 'United States', 'City': 'Miami', 'Exit Date': '2021-05-01T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'RRLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E00431', 'Full Name': 'Skylar Doan', 'Job Title': 'Sr. Business Partner', 'Department': 'Human Resources', 'Business Unit': 'Research & Development', 'Gender': 'Female', 'Ethnicity': 'Asian', 'Age': 58, 'Hire Date': '1994-08-21T00:00:00', 'Annual Salary': 93102, 'Bonus %': 0, 'Country': 'United States', 'City': 'Seattle', 'Exit Date': '2013-12-13T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'bRLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E02639', 'Full Name': 'Hadley Parker', 'Job Title': 'Vice President', 'Department': 'Marketing', 'Business Unit': 'Corporate', 'Gender': 'Female', 'Ethnicity': 'Black', 'Age': 30, 'Hire Date': '2016-09-21T00:00:00', 'Annual Salary': 221217, 'Bonus %': 0.32, 'Country': 'United States', 'City': 'Columbus', 'Exit Date': '2017-09-25T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'iRLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E02813', 'Full Name': 'Kai Chow', 'Job Title': 'Engineering Manager', 'Department': 'Engineering', 'Business Unit': 'Corporate', 'Gender': 'Male', 'Ethnicity': 'Asian', 'Age': 45, 'Hire Date': '2001-04-12T00:00:00', 'Annual Salary': 95743, 'Bonus %': 0.15, 'Country': 'United States', 'City': 'Austin', 'Exit Date': '2010-01-15T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'khLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E04035', 'Full Name': 'Penelope Johnson', 'Job Title': 'Sr. Analyst', 'Department': 'Marketing', 'Business Unit': 'Research & Development', 'Gender': 'Female', 'Ethnicity': 'Caucasian', 'Age': 34, 'Hire Date': '2012-06-25T00:00:00', 'Annual Salary': 83066, 'Bonus %': 0, 'Country': 'United States', 'City': 'Chicago', 'Exit Date': '2013-06-05T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'lBLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E00276', 'Full Name': 'Ezekiel Jordan', 'Job Title': 'Sr. Manger', 'Department': 'Accounting', 'Business Unit': 'Corporate', 'Gender': 'Male', 'Ethnicity': 'Caucasian', 'Age': 33, 'Hire Date': '2013-02-10T00:00:00', 'Annual Salary': 144231, 'Bonus %': 0.14, 'Country': 'United States', 'City': 'Columbus', 'Exit Date': '2020-07-17T00:00:00'}}, {'_index': 'xlsx_index', '_id': 'mBLqbpQBXUp6I3aU7rs2', '_score': 1.0, '_source': {'EEID': 'E00119', 'Full Name': 'Jack Maldonado', 'Job Title': 'Director', 'Department': 'Engineering', 'Business Unit': 'Research & Development', 'Gender': 'Male', 'Ethnicity': 'Latino', 'Age': 31, 'Hire Date': '2020-08-26T00:00:00', 'Annual Salary': 189290, 'Bonus %': 0.22, 'Country': 'Brazil', 'City': 'Sao Paulo', 'Exit Date': '2020-09-25T00:00:00'}}]}}\n"
     ]
    }
   ],
   "source": [
    "QUERY = \"List of employee under Sales depat\"\n",
    "\n",
    "query = {\n",
    "    \"match_all\": {}\n",
    "}\n",
    "response = elasticsearch_client.search(index='xlsx_index', query=query, size=20)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m results \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results: \n\u001b[1;32m----> 5\u001b[0m     content \u001b[38;5;241m=\u001b[39m content \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_source\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=============================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "\n",
    "content =\"\"\n",
    "results = response[\"hits\"][\"hits\"]\n",
    "\n",
    "for result in results: \n",
    "    content = content + \"\\n\" + result[\"_source\"][\"text\"]\n",
    "    print(result[\"_source\"][\"text\"])\n",
    "    print(\"=============================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"Phi-4\",\n",
    "    temperature=0,\n",
    "    api_key=\"dummy-key\",  \n",
    "    base_url=\"http://127.0.0.1:8080/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"\"\"\n",
    "            You are an assistant for question-answering tasks. \n",
    "            Use the following pieces of retrieved context to answer the question. \n",
    "            If you don't know the answer, just say that you don't know. Keep the answer concise. \n",
    "            Context: {context} \n",
    "            \"\"\"\n",
    "        ),\n",
    "        (\"human\", \"Question: {question} Answer/s: \")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "answer = chain.invoke(\n",
    "    {\n",
    "        \"context\": content,\n",
    "        \"question\": QUERY\n",
    "    }\n",
    ")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guy Holland is the Global Leader of KPMG's CIO Center of Excellence and the Group Executive of Technology and Group Chief Information Officer at the Commonwealth Bank of Australia.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Excel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import json\n",
    "from elasticsearch.helpers import bulk\n",
    "\n",
    "xlsx_file = \"../data/EmployeeSampleData/Employee Sample Data.xlsx\"\n",
    "\n",
    "workbook = openpyxl.load_workbook(xlsx_file)\n",
    "sheet = workbook.active\n",
    "\n",
    "def prepare_data(sheet):\n",
    "    headers = [cell.value for cell in sheet[1]]\n",
    "    documents = []\n",
    "\n",
    "    for row in sheet.iter_rows(min_row=2, values_only=True):\n",
    "        doc = {}\n",
    "        for col, value in zip(headers, row):\n",
    "            doc[col] = value\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents\n",
    "\n",
    "documents = prepare_data(sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 1000 documents into Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# # Initialize Elasticsearch client\n",
    "elasticsearch_client = Elasticsearch(\n",
    "    hosts=\"https://360399a232d44176a9811dcf98c25240.eastus2.azure.elastic-cloud.com:443\",\n",
    "    basic_auth=(\"elastic\", \"zfNThaF3pna6JHmcGPIsntKP\")\n",
    ")\n",
    "\n",
    "elasticsearch_client.ping()\n",
    "\n",
    "# Path to your .xlsx file\n",
    "xlsx_file = \"../data/EmployeeSampleData/Employee Sample Data.xlsx\"\n",
    "\n",
    "# Load the workbook and select the active sheet\n",
    "workbook = openpyxl.load_workbook(xlsx_file)\n",
    "sheet = workbook.active\n",
    "\n",
    "# Helper function to handle empty dates and parse valid dates\n",
    "def parse_date(date_value):\n",
    "    if not date_value or date_value == '':  # Handle empty or None dates\n",
    "        return None  # You can set a default date like '1970-01-01' if required\n",
    "    try:\n",
    "        # Attempt to parse the date (assuming the format yyyy-MM-dd)\n",
    "        return datetime.strptime(str(date_value), \"%Y-%m-%d\").date()\n",
    "    except ValueError:\n",
    "        return None  # Return None if the date format is invalid\n",
    "\n",
    "# Helper function to prepare data from the sheet\n",
    "def prepare_data(sheet):\n",
    "    headers = [cell.value for cell in sheet[1]]  # Extract headers from the first row\n",
    "    documents = []\n",
    "\n",
    "    for row in sheet.iter_rows(min_row=2, values_only=True):  # Start from the second row\n",
    "        doc = {}\n",
    "        for col, value in zip(headers, row):\n",
    "            if col == \"Exit Date\":  # Handle the \"Exit Date\" field specifically\n",
    "                doc[col] = parse_date(value)  # Use the date parser for the \"Exit Date\"\n",
    "            else:\n",
    "                doc[col] = value\n",
    "        documents.append(doc)\n",
    "\n",
    "    return documents\n",
    "\n",
    "# Prepare documents\n",
    "documents = prepare_data(sheet)\n",
    "\n",
    "# Index name for Elasticsearch\n",
    "index_name = 'xlsx_index'\n",
    "\n",
    "# Bulk index function\n",
    "def bulk_index_documents(documents, index_name, elasticsearch_client):\n",
    "    actions = []\n",
    "    for doc in documents:\n",
    "        action = {\n",
    "            \"_op_type\": \"index\",   # Default to \"index\" operation\n",
    "            \"_index\": index_name,\n",
    "            \"_source\": doc         # The document to index\n",
    "        }\n",
    "        actions.append(action)\n",
    "\n",
    "    try:\n",
    "        # Bulk helper function\n",
    "        success, failed = helpers.bulk(elasticsearch_client, actions, raise_on_error=False)\n",
    "        if failed:\n",
    "            print(f\"Failed to index {len(failed)} documents.\")\n",
    "            # Print the detailed error messages for failed documents\n",
    "            for failure in failed:\n",
    "                print(failure)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during bulk indexing: {str(e)}\")\n",
    "\n",
    "# Check if the index exists, create if not\n",
    "if not elasticsearch_client.indices.exists(index=index_name):\n",
    "    elasticsearch_client.indices.create(index=index_name)\n",
    "\n",
    "# Perform bulk indexing\n",
    "bulk_index_documents(documents, index_name, elasticsearch_client)\n",
    "\n",
    "print(f\"Successfully indexed {len(documents)} documents into Elasticsearch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"List of employee under Sales depat\"\n",
    "\n",
    "ELQL_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are expert in Elasticsearch Query Language EL|QL. Your task is to write the EL|QL query to answer the user's question with the elasticsearch index details.\n",
    "    Elasticsearch Index Mapping details: {mapping}\n",
    "    User's question: {question}\n",
    "\n",
    "    Sample EL|QL query:\n",
    "    FROM library | KEEP author, name, page_count, release_date | SORT page_count DESC | LIMIT 5\",\n",
    "\n",
    "    EL|QL:\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"Qwen-7B\",\n",
    "    temperature=0,\n",
    "    api_key=\"dummy-key\",  \n",
    "    base_url=\"http://127.0.0.1:8080/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "تُعدّ تقنية الذكاء الاصطناعي من التقنيات الحديثة التي أصبحت جزءًا لا يتجزأ من حياتنا اليومية، حيث أصبحت متغلغلة في العديد من المجالات، من السيارات ذاتية القيادة إلى الأجهزة المنزلية الذكية. وتُستخدم في العديد من التطبيقات، مثل التعرف على الكلام، والترجمة، والرؤية الحاسوبية، والتحكم بالروبوتات، وغيرها.\n",
      "\n",
      "تُعتَبر الذكاء الاصطناعي من التقنيات التي تحتاج إلى الكثير من البيانات والمعلومات لإعدادها وتدريبها، حيث يتطلب من الخبراء جمع كميات هائلة من البيانات من مصادر مختلفة، وتنظيمها وتصنيفها، ثم تدريب الأنظمة الذكية عليها. وتُعدّ هذه العملية من أكثر مراحل تطوير الذكاء الاصطناعي صعوبة، حيث تتطلب وقتًا طويلًا وتكلفة عالية.\n",
      "\n",
      "تُستخدم تقنية الذكاء الاصطناعي في العديد من المجالات، مثل الرعاية الصحية، حيث يمكن استخدامها في تشخيص الأمراض، وتطوير علاجات جديدة، وتوفير الرعاية الصحية عن بعد. كما تُستخدم في مجال التعليم، حيث يمكن استخدامها في تخصيص التعليم، وتوفير تجربة تعليمية مخصصة لكل طالب. وتُستخدم أيضًا في مجال الأعمال، حيث يمكن استخدامها في تحليل البيانات، وتوقع الاتجاهات، وتطوير استراتيجيات الأعمال.\n",
      "\n",
      "تُعدّ تقنية الذكاء الاصطناعي من التقنيات التي لها تأثير كبير على حياتنا اليومية، حيث أصبحت جزءًا لا يتجزأ من العديد من الأجهزة التي نستخدمها يوميًا، مثل الهواتف الذكية، والأجهزة المنزلية، والسيارات. وتُعدّ من التقنيات التي ستتطور أكثر في المستقبل، وستؤثر في العديد من المجالات الأخرى.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"Write the essary in Arabic about AI technology with 500 words\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = \"\"\"{\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"Age\": {\n",
    "        \"type\": \"long\"\n",
    "      },\n",
    "      \"Annual Salary\": {\n",
    "        \"type\": \"long\"\n",
    "      },\n",
    "      \"Bonus %\": {\n",
    "        \"type\": \"float\"\n",
    "      },\n",
    "      \"Business Unit\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"City\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Country\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Department\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"EEID\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Ethnicity\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Exit Date\": {\n",
    "        \"type\": \"date\"\n",
    "      },\n",
    "      \"Full Name\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Gender\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Hire Date\": {\n",
    "        \"type\": \"date\"\n",
    "      },\n",
    "      \"Job Title\": {\n",
    "        \"type\": \"text\",\n",
    "        \"fields\": {\n",
    "          \"keyword\": {\n",
    "            \"type\": \"keyword\",\n",
    "            \"ignore_above\": 256\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```ql\n",
      "FROM employees | KEEP Full Name, Department | FILTER Department = \"Sales\" | PROJECT Full Name\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "1. **FROM employees:** Specifies the index name (`employees`).\n",
      "2. **KEEP Full Name, Department:** Retains only the `FullName` and `Department` fields for the result.\n",
      "3. **FILTER Department = \"Sales\":** Filters the documents to include only those where the `Department` field is \"Sales\".\n",
      "4. **PROJECT Full Name:** Projects (selects) only the `FullName` field from the filtered documents.\n",
      "\n",
      "This query will return a list of employee names (`FullName`) who are part of the \"Sales\" department.\n"
     ]
    }
   ],
   "source": [
    "chain = ELQL_PROMPT | llm\n",
    "\n",
    "answer = chain.invoke(\n",
    "    {\n",
    "        \"mapping\": mapping,\n",
    "        \"question\": QUERY\n",
    "    }\n",
    ")\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM xlsx_index | WHERE Department.keyword == \"Sales\" | KEEP `Full Name`, EEID, `Job Title`, Department\n",
    "FROM xlsx_index | KEEP `Full Name`, Department | FILTER Department = \"Sales\" | PROJECT `Full Name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "BadRequestError(400, 'parsing_exception', \"line 1:50: mismatched input 'FILTER' expecting {'dissect', 'drop', 'enrich', 'eval', 'grok', 'keep', 'limit', 'mv_expand', 'rename', 'sort', 'stats', 'where'}\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43melasticsearch_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtxt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mFROM xlsx_index | KEEP `Full Name`, Department | FILTER Department = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSales\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m | PROJECT `Full Name`\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp)\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py:455\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\_sync\\client\\esql.py:138\u001b[0m, in \u001b[0;36mEsqlClient.query\u001b[1;34m(self, query, columnar, delimiter, drop_null_columns, error_trace, filter, filter_path, format, human, locale, params, pretty, profile, tables, body)\u001b[0m\n\u001b[0;32m    136\u001b[0m         __body[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tables\n\u001b[0;32m    137\u001b[0m __headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mesql.query\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:423\u001b[0m, in \u001b[0;36mNamespacedClient.perform_request\u001b[1;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mperform_request\u001b[39m(\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    412\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;66;03m# Use the internal clients .perform_request() implementation\u001b[39;00m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;66;03m# so we take advantage of their transport options.\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:271\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[1;34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mperform_request\u001b[39m(\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    257\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    265\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ApiResponse[Any]:\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_otel\u001b[38;5;241m.\u001b[39mspan(\n\u001b[0;32m    267\u001b[0m         method,\n\u001b[0;32m    268\u001b[0m         endpoint_id\u001b[38;5;241m=\u001b[39mendpoint_id,\n\u001b[0;32m    269\u001b[0m         path_parts\u001b[38;5;241m=\u001b[39mpath_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[0;32m    270\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[1;32m--> 271\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m         otel_span\u001b[38;5;241m.\u001b[39mset_elastic_cloud_metadata(response\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\tshar\\.conda\\envs\\ADEO\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:352\u001b[0m, in \u001b[0;36mBaseClient._perform_request\u001b[1;34m(self, method, path, params, headers, body, otel_span)\u001b[0m\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(meta\u001b[38;5;241m.\u001b[39mstatus, ApiError)(\n\u001b[0;32m    353\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage, meta\u001b[38;5;241m=\u001b[39mmeta, body\u001b[38;5;241m=\u001b[39mresp_body\n\u001b[0;32m    354\u001b[0m     )\n\u001b[0;32m    356\u001b[0m \u001b[38;5;66;03m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verified_elasticsearch:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: BadRequestError(400, 'parsing_exception', \"line 1:50: mismatched input 'FILTER' expecting {'dissect', 'drop', 'enrich', 'eval', 'grok', 'keep', 'limit', 'mv_expand', 'rename', 'sort', 'stats', 'where'}\")"
     ]
    }
   ],
   "source": [
    "resp = elasticsearch_client.esql.query(\n",
    "    format=\"txt\",\n",
    "    query=\"\"\"FROM xlsx_index | KEEP `Full Name`, Department | FILTER Department = \"Sales\" | PROJECT `Full Name`\"\"\",\n",
    "    )\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
